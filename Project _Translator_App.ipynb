{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNhf3pIul6weNAFibABoRU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Namanbansal9414/User-Referral-Rewards/blob/main/Project%20_Translator_App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wrJFoIzp2G8y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel:\n",
        "    def __init__(self):\n",
        "        # Placeholders for sub-models and tools\n",
        "        self.language_detection_model = None\n",
        "        self.language_detection_cv = None\n",
        "\n",
        "        self.french_translation_model = None\n",
        "        self.french_cv = None\n",
        "        self.french_label_encoder = None\n",
        "\n",
        "        self.urdu_translation_model = None\n",
        "        self.urdu_cv = None\n",
        "        self.urdu_label_encoder = None\n",
        "\n",
        "    def train_language_detection(self, path=\"/content/dataset.csv\"):\n",
        "        data = pd.read_csv(path)\n",
        "        X = np.array(data[\"Text\"])\n",
        "        y = np.array(data[\"language\"])\n",
        "        self.language_detection_cv = CountVectorizer()\n",
        "        X_vec = self.language_detection_cv.fit_transform(X)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.33, random_state=42)\n",
        "        self.language_detection_model = MultinomialNB()\n",
        "        self.language_detection_model.fit(X_train, y_train)\n",
        "        acc = self.language_detection_model.score(X_test, y_test)\n",
        "        print(f\"Language Detection Accuracy: {acc:.4f}\")\n",
        "\n",
        "    def train_french_translation(self, path=\"/content/data1.csv\"):\n",
        "        data = pd.read_csv(path)\n",
        "        X = np.array(data['English'])\n",
        "        y = np.array(data['French'])\n",
        "        self.french_label_encoder = LabelEncoder()\n",
        "        y_encoded = self.french_label_encoder.fit_transform(y)\n",
        "        X_train, _, y_train, _ = train_test_split(X, y_encoded, test_size=0.99, random_state=42)\n",
        "        self.french_cv = CountVectorizer()\n",
        "        X_train_vec = self.french_cv.fit_transform(X_train)\n",
        "        self.french_translation_model = MultinomialNB()\n",
        "        self.french_translation_model.fit(X_train_vec, y_train)\n",
        "        acc = self.french_translation_model.score(X_train_vec, y_train)\n",
        "        print(f\"English to French Translation Accuracy: {acc:.4f}\")\n",
        "\n",
        "    def train_urdu_translation(self, path=\"/content/EU.xlsx\"):\n",
        "        data = pd.read_excel(path)\n",
        "        X = np.array(data['English'])\n",
        "        y = np.array(data['Urdu'])\n",
        "        self.urdu_label_encoder = LabelEncoder()\n",
        "        y_encoded = self.urdu_label_encoder.fit_transform(y)\n",
        "        X_train, _, y_train, _ = train_test_split(X, y_encoded, test_size=0.42, random_state=42)\n",
        "        self.urdu_cv = CountVectorizer()\n",
        "        X_train_vec = self.urdu_cv.fit_transform(X_train)\n",
        "        self.urdu_translation_model = MultinomialNB()\n",
        "        self.urdu_translation_model.fit(X_train_vec, y_train)\n",
        "        acc = self.urdu_translation_model.score(X_train_vec, y_train)\n",
        "        print(f\"English to Urdu Translation Accuracy: {acc:.4f}\")\n",
        "\n",
        "    def detect_language(self, text):\n",
        "        x_vec = self.language_detection_cv.transform([text])\n",
        "        pred = self.language_detection_model.predict(x_vec)[0]\n",
        "        return pred\n",
        "\n",
        "    def translate(self, text, target_language):\n",
        "        if target_language.lower() == 'french':\n",
        "            x_vec = self.french_cv.transform([text])\n",
        "            pred_label = self.french_translation_model.predict(x_vec)[0]\n",
        "            return self.french_label_encoder.inverse_transform([pred_label])[0]\n",
        "        elif target_language.lower() == 'urdu':\n",
        "            x_vec = self.urdu_cv.transform([text])\n",
        "            pred_label = self.urdu_translation_model.predict(x_vec)[0]\n",
        "            return self.urdu_label_encoder.inverse_transform([pred_label])[0]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported target language: {target_language}\")"
      ],
      "metadata": {
        "id": "OC4EyrqoAVRb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel()\n",
        "\n",
        "print(\"Training language detection model...\")\n",
        "model.train_language_detection()\n",
        "\n",
        "print(\"Training English to French translation model...\")\n",
        "model.train_french_translation()\n",
        "\n",
        "print(\"Training English to Urdu translation model...\")\n",
        "model.train_urdu_translation()\n",
        "\n",
        "# Save the entire combined model to a pickle file\n",
        "with open(\"/content/combined_language_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model, f)\n",
        "print(\"Combined model saved as combined_language_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuuAD52t3NbT",
        "outputId": "dc7593bf-d74a-4a96-b99a-0c0a4bcf6d8a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training language detection model...\n",
            "Language Detection Accuracy: 0.9532\n",
            "Training English to French translation model...\n",
            "English to French Translation Accuracy: 0.9818\n",
            "Training English to Urdu translation model...\n",
            "English to Urdu Translation Accuracy: 0.2782\n",
            "Combined model saved as combined_language_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio -q\n",
        "import gradio as gr\n",
        "import pickle\n",
        "\n",
        "with open(\"/content/combined_language_model.pkl\", \"rb\") as f:\n",
        "    language_model = pickle.load(f)\n",
        "\n",
        "\n",
        "def process_input(user_text, task):\n",
        "    if not user_text.strip():\n",
        "        return \"‚ö†Ô∏è Please enter some text.\"\n",
        "    if task == \"Detect Language\":\n",
        "        return f\"üåê **Detected Language:** `{language_model.detect_language(user_text)}`\"\n",
        "    elif task == \"Translate to French\":\n",
        "        return f\"üá´üá∑ **French Translation:**\\n\\n`{language_model.translate(user_text, 'french')}`\"\n",
        "    elif task == \"Translate to Urdu\":\n",
        "        return f\"üáµüá∞ **Urdu Translation:**\\n\\n`{language_model.translate(user_text, 'urdu')}`\"\n",
        "    else:\n",
        "        return \"‚ùå Invalid task selected.\"\n",
        "\n",
        "# Enhanced HTML with modern styling\n",
        "description_html = \"\"\"\n",
        "<div style=\"text-align: center; font-family: 'Segoe UI', sans-serif; margin-bottom: 20px;\">\n",
        "    <h1 style=\"color: #1e88e5; font-size: 2.8em;\">üåç Multilingual AI Assistant</h1>\n",
        "    <p style=\"font-size: 1.2em; color: #444;\">\n",
        "        Easily detect language üåê or translate English to <b style=\"color:#1e88e5;\">French</b> üá´üá∑ or <b style=\"color:#388e3c;\">Urdu</b> üáµüá∞\n",
        "    </p>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "footer_html = \"\"\"\n",
        "<div style=\"text-align: center; margin-top: 40px; color: #888; font-size: 0.9em; font-family: 'Segoe UI', sans-serif;\">\n",
        "    <hr style=\"margin-bottom: 15px;\">\n",
        "    <p>Built with ‚ù§Ô∏è using Python, Scikit-learn, and Gradio</p>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "# Interface with enhanced style\n",
        "interface = gr.Interface(\n",
        "    fn=process_input,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=3, placeholder=\"Type or paste your text here...\", label=\"‚úèÔ∏è Enter Text\"),\n",
        "        gr.Dropdown(\n",
        "            choices=[\"Detect Language\", \"Translate to French\", \"Translate to Urdu\"],\n",
        "            label=\"üß≠ Select Action\",\n",
        "            value=\"Detect Language\"\n",
        "        ),\n",
        "    ],\n",
        "    outputs=gr.Markdown(label=\"üîç Result\"),\n",
        "    description=description_html,\n",
        "    article=footer_html,\n",
        "    theme=\"default\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "LcRK9SXKFxCf",
        "outputId": "2226ac5e-28fc-4714-a762-2f5d616fa986"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:416: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7d2bfe1c6851a2163b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7d2bfe1c6851a2163b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f-y2z04TFwvY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}